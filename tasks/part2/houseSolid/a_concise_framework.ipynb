{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "913d4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, mutual_info_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b051ca",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f9536",
   "metadata": {},
   "source": [
    "### Обработка Null (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "acf99cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_NAN(df, test = 0):\n",
    "\n",
    "    print(f\"Начальная размерность: {df.shape}\")\n",
    "    print(f\"Количество пропусков: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    # удаляем все столбцы, в которых слишком много пропущенных значений\n",
    "    num_str = df.shape[0]\n",
    "    sum_null_in_cols = df.isnull().sum()\n",
    "    missing_cols = sum_null_in_cols[sum_null_in_cols > num_str * 0.1]\n",
    "    df = df.drop(columns=missing_cols.index.tolist())\n",
    "\n",
    "    print(f\"Размерность после первичной обработки: {df.shape}\")\n",
    "    print(f\"Количество пропусков: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    # разделяем данные на признаки и целевую переменную\n",
    "\n",
    "    if not test: target = np.log1p(df[\"SalePrice\"]) # логорифмируем, чтобы выбросы не так сильно влияли\n",
    "    feature = df.drop(columns=['SalePrice']) if not test else df\n",
    "\n",
    "    # заполняем оставшиеся пропуски\n",
    "    num_features = feature.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    cat_features = feature.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    imputer_num = KNNImputer(n_neighbors = 5, weights = \"distance\")\n",
    "    imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "    feature[num_features] = imputer_num.fit_transform(feature[num_features])\n",
    "    feature[cat_features] = imputer_cat.fit_transform(feature[cat_features])\n",
    "\n",
    "    print(f\"Размерность после вторичной обработки обработки: {feature.shape}\")\n",
    "    print(f\"Количество пропусков: {feature.isnull().sum().sum()}\")\n",
    "\n",
    "    if not test:\n",
    "        return feature, target # выводим признаки и целевую переменную\n",
    "    else:\n",
    "        return feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d3cc7",
   "metadata": {},
   "source": [
    "### Обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73afad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_cat_features(feature):\n",
    "    # Признаки обрабатываются различным образом в зависимости от данных внутри (тип обработки подобран с помощью ChatGPT)\n",
    "    print('\\n', \"Начало обработки категориальных признаков\", sep =\"\")\n",
    "\n",
    "    feature = pd.get_dummies(feature, columns=['MSZoning', 'Street', 'LotConfig', 'BldgType', 'HouseStyle', \n",
    "                                    'RoofStyle', 'RoofMatl', 'Foundation', 'Heating', 'CentralAir', \n",
    "                                    'PavedDrive', 'SaleType', 'SaleCondition', 'Utilities'], drop_first=True)\n",
    "\n",
    "    ordinal_cols = [\n",
    "        'LotShape', 'LandSlope', 'ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual', \n",
    "        'Functional', 'LandContour', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n",
    "        'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'GarageType', 'GarageFinish', \n",
    "        'GarageQual', 'GarageCond'\n",
    "    ]\n",
    "\n",
    "    ordinal_mapping = [\n",
    "        ['Reg', 'IR1', 'IR2', 'IR3'], \n",
    "        ['Gtl', 'Mod', 'Sev'], \n",
    "        ['Ex', 'Gd', 'TA', 'Fa'], \n",
    "        ['Ex', 'Gd', 'TA', 'Fa', 'Po'], \n",
    "        ['Ex', 'Gd', 'TA', 'Fa', 'Po'], \n",
    "        ['Ex', 'Gd', 'TA', 'Fa'], \n",
    "        ['Typ', 'Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev'],\n",
    "        ['Bnk', 'Lvl', 'HLS', 'Low'],\n",
    "        ['Ex', 'Gd', 'TA', 'Fa'],  \n",
    "        ['TA', 'Gd', 'Fa', 'Po'], \n",
    "        ['No', 'Gd', 'Mn', 'Av'],  \n",
    "        ['GLQ', 'ALQ', 'Unf', 'Rec', 'BLQ', 'LwQ'],  \n",
    "        ['Unf', 'BLQ', 'ALQ', 'Rec', 'LwQ', 'GLQ'], \n",
    "        ['SBrkr', 'FuseF', 'FuseA', 'FuseP', 'Mix'],  \n",
    "        ['Attchd', 'Detchd', 'BuiltIn', 'CarPort', 'Basment', '2Types'],  \n",
    "        ['RFn', 'Unf', 'Fin'],  \n",
    "        ['TA', 'Fa', 'Gd', 'Ex', 'Po'], \n",
    "        ['TA', 'Fa', 'Gd', 'Po', 'Ex']  \n",
    "    ]\n",
    "\n",
    "    encoder = OrdinalEncoder(categories=ordinal_mapping)\n",
    "\n",
    "    feature[ordinal_cols] = encoder.fit_transform(feature[ordinal_cols])\n",
    "\n",
    "    label_cols = ['Neighborhood', 'Condition1', 'Condition2', 'Exterior1st', 'Exterior2nd']\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for col in label_cols:\n",
    "        feature[col] = le.fit_transform(feature[col])\n",
    "\n",
    "\n",
    "    cat_features = feature.select_dtypes(include=['object']).columns.tolist()\n",
    "    print(f\"Количество признаков не переведенных в числовые: {len(cat_features)}\")\n",
    "\n",
    "    if len(cat_features) > 0:\n",
    "        for col in feature.columns:\n",
    "            if feature[col].dtype not in [\"float64\", \"int64\", \"bool\"]:\n",
    "                print(f\"Col: {col}, dtype: {feature[col].dtype}, unique: {feature[col].unique()}\")\n",
    "\n",
    "    print(\"Обработка категориальных признаков закончена\")\n",
    "\n",
    "    return feature # отдаем обработанные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d41a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_separation(feature, target):\n",
    "    print('\\n', \"Разделение данных на тренировочную, валидационную и тестовую выборку началось.\", sep = \"\")\n",
    "    X_train, x_vt, Y_train, y_vt = train_test_split(feature, target, test_size= 0.4, random_state=42)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(x_vt, y_vt, test_size=0.5, random_state=42)\n",
    "    Y_test = np.expm1(Y_test)\n",
    "    print(\"Разделение данных завершено.\")\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdc73019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальная размерность: (1460, 81)\n",
      "Количество пропусков: 7829\n",
      "Размерность после первичной обработки: (1460, 74)\n",
      "Количество пропусков: 601\n",
      "Размерность после вторичной обработки обработки: (1460, 73)\n",
      "Количество пропусков: 0\n",
      "\n",
      "Начало обработки категориальных признаков\n",
      "Количество признаков не переведенных в числовые: 0\n",
      "Обработка категориальных признаков закончена\n",
      "\n",
      "Разделение данных на тренировочную, валидационную и тестовую выборку началось.\n",
      "Разделение данных завершено.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"data\\train.csv\")\n",
    "feature, target = data_processing_NAN(df = df)\n",
    "feature = data_processing_cat_features(feature= feature)\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = data_separation(feature = feature, target = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211c04e",
   "metadata": {},
   "source": [
    "# Функция подсчета RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29baa00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(model, select_col = X_train.columns):\n",
    "    predicted = np.expm1(model.predict(X_test[select_col]))\n",
    "\n",
    "    loss = root_mean_squared_error(predicted, Y_test)\n",
    "\n",
    "    print(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad14df",
   "metadata": {},
   "source": [
    "*функция для красивых выводов признаков (понадобиться далее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b94c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature(feature, title = \"\"):\n",
    "    if title:\n",
    "        print(title)\n",
    "\n",
    "    for i in range(0, len(feature), 5):\n",
    "        print(*feature[i: i + 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0653c",
   "metadata": {},
   "source": [
    "# Подбор признаков для моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1407d",
   "metadata": {},
   "source": [
    "NOTE: Какой процент брать для отбора признаков был подобран эксперементально. Далее вы поймете о чем речь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f6d53",
   "metadata": {},
   "source": [
    "### Подбор признаков для RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c773166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplest_model_RF(select_col = X_train.columns, title = \"\"):\n",
    "    start = time.time()\n",
    "\n",
    "    if title:\n",
    "        print(title, '\\n')\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train[select_col], Y_train)\n",
    "\n",
    "    RMSE(model, select_col)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"time: {end - start}\", '\\n')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85c2472c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель RF для подбора признаков \n",
      "\n",
      "21200.34528869388\n",
      "time: 2.891062021255493 \n",
      "\n",
      "Лучшие признаки для RF:\n",
      "LotArea Neighborhood OverallQual OverallCond YearBuilt\n",
      "YearRemodAdd BsmtQual BsmtFinSF1 BsmtUnfSF TotalBsmtSF\n",
      "1stFlrSF 2ndFlrSF GrLivArea Fireplaces GarageCars\n",
      "GarageArea OpenPorchSF MSZoning_RM CentralAir_Y\n"
     ]
    }
   ],
   "source": [
    "model_RF = simplest_model_RF(title=\"Модель RF для подбора признаков\")\n",
    "\n",
    "coef = model_RF.feature_importances_ * 100\n",
    "\n",
    "table_coef = pd.DataFrame({\n",
    "    'Feature': X_train.columns.tolist(),\n",
    "    'Persentage importance': coef\n",
    "})\n",
    "\n",
    "best_feature_RF = table_coef[table_coef[\"Persentage importance\"] > 0.5][\"Feature\"].tolist()\n",
    "print_feature(feature = best_feature_RF, title = \"Лучшие признаки для RF:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65312df3",
   "metadata": {},
   "source": [
    "### Подбор признаков для XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d8324fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = X_train.astype({col: \"int32\" for col in X_train.select_dtypes(include=\"bool\").columns})\n",
    "X_test_ = X_test.astype({col: \"int32\" for col in X_test.select_dtypes(include=\"bool\").columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a763c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_model_simplest(select_col = X_train_.columns, title = \"\"):\n",
    "    start = time.time()\n",
    "\n",
    "    if title:\n",
    "        print(title, '\\n')\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",  \n",
    "        n_estimators=500,              \n",
    "        learning_rate=0.05,           \n",
    "        max_depth=6,                  \n",
    "        subsample=0.8,                \n",
    "        colsample_bytree=0.8,          \n",
    "        random_state=42\n",
    "        )\n",
    "\n",
    "    model.fit(X_train_[select_col], Y_train)\n",
    "\n",
    "    predicted = np.expm1(model.predict(X_test_[select_col]))\n",
    "\n",
    "    loss = root_mean_squared_error(predicted, Y_test)\n",
    "\n",
    "    print(f\"RMSE: {loss}\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"time: {end - start}\", '\\n')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48bda130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель XGB для подбора признаков \n",
      "\n",
      "RMSE: 19151.956099428706\n",
      "time: 2.4768588542938232 \n",
      "\n",
      "Лучшие признаки для XGB:\n",
      "Id MSSubClass LotArea LotShape LandContour\n",
      "LandSlope Neighborhood Condition1 Condition2 OverallQual\n",
      "OverallCond YearBuilt YearRemodAdd Exterior1st Exterior2nd\n",
      "MasVnrArea ExterQual ExterCond BsmtQual BsmtCond\n",
      "BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2\n",
      "BsmtUnfSF TotalBsmtSF HeatingQC Electrical 1stFlrSF\n",
      "2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath\n",
      "FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual\n",
      "TotRmsAbvGrd Functional Fireplaces GarageType GarageYrBlt\n",
      "GarageFinish GarageCars GarageArea GarageQual GarageCond\n",
      "WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch\n",
      "PoolArea MiscVal MoSold YrSold MSZoning_FV\n",
      "MSZoning_RH MSZoning_RL MSZoning_RM LotConfig_CulDSac LotConfig_FR2\n",
      "LotConfig_FR3 LotConfig_Inside BldgType_2fmCon BldgType_Duplex BldgType_Twnhs\n",
      "BldgType_TwnhsE HouseStyle_1.5Unf HouseStyle_1Story HouseStyle_2.5Unf HouseStyle_2Story\n",
      "HouseStyle_SFoyer HouseStyle_SLvl RoofStyle_Gable RoofStyle_Hip RoofMatl_CompShg\n",
      "Foundation_CBlock Foundation_PConc Foundation_Slab Foundation_Wood Heating_GasA\n",
      "Heating_Grav CentralAir_Y PavedDrive_P PavedDrive_Y SaleType_CWD\n",
      "SaleType_ConLD SaleType_New SaleType_WD SaleCondition_Alloca SaleCondition_Family\n",
      "SaleCondition_Normal SaleCondition_Partial\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBoost_model_simplest(title=\"Модель XGB для подбора признаков\")\n",
    "\n",
    "coef = model_xgb.feature_importances_ * 100\n",
    "\n",
    "table_coef = pd.DataFrame({\n",
    "    'Feature': X_train.columns.tolist(),\n",
    "    'Persentage importance': coef\n",
    "})\n",
    "\n",
    "feature_more_0001_per_imp = table_coef[table_coef[\"Persentage importance\"] > 0.001][\"Feature\"].tolist()\n",
    "\n",
    "best_feature_XGB = feature_more_0001_per_imp\n",
    "\n",
    "print_feature(feature = best_feature_XGB, title = \"Лучшие признаки для XGB:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9e612",
   "metadata": {},
   "source": [
    "### Для KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9dc43814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выбраны признаки: ['KitchenQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', '1stFlrSF', 'BsmtQual', 'OverallQual']\n"
     ]
    }
   ],
   "source": [
    "#Выделим признаки пересечением тех признаков что имеют не нулевлй коэффициент у lasso\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", Lasso(alpha=0.05))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, Y_train)\n",
    "\n",
    "coef = pipe.named_steps[\"model\"].coef_\n",
    "select_feature_lasso = X_train.columns[coef != 0]\n",
    "\n",
    "#И лучшие признаки отобранные с помощью SelectKBest\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selector\", SelectKBest(score_func=mutual_info_regression, k=10))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, Y_train)\n",
    "\n",
    "coef = pipe.named_steps[\"selector\"].get_support()\n",
    "select_feature_SelKBest = X_train.columns[coef != 0]\n",
    "\n",
    "#Вот и пересечение признаков\n",
    "best_feature_KNN = list(set(select_feature_lasso).intersection(set(select_feature_SelKBest)))\n",
    "\n",
    "print(f\"Выбраны признаки: {best_feature_KNN}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fd168",
   "metadata": {},
   "source": [
    "# Создание и обучение основных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa1764a",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88b0603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_RF(save_model = 0, title = \"\", selected_cols = X_train.columns):\n",
    "    start = time.time()\n",
    "\n",
    "    if title:\n",
    "        print(title)\n",
    "\n",
    "    param_grid_RF = {\n",
    "        'n_estimators': [40, 100, 300, 550, 1000],\n",
    "        'max_depth': [7, 9, 11],\n",
    "        'min_samples_split': [2, 3, 4, 6]\n",
    "    }\n",
    "\n",
    "    model_RF = RandomForestRegressor()\n",
    "\n",
    "    grid_search_RF = GridSearchCV(model_RF, param_grid = param_grid_RF, cv = 4, scoring = \"neg_root_mean_squared_error\", n_jobs = -1)\n",
    "\n",
    "    grid_search_RF.fit(X_val[selected_cols], Y_val) #обучаем на валидационной выборке для подбора гиперпараметров\n",
    "\n",
    "    best_param = grid_search_RF.best_params_\n",
    "\n",
    "    print(\"Best params:\", best_param)\n",
    "\n",
    "    model_RF = RandomForestRegressor(**best_param) #теперь обучаем основную модель\n",
    "\n",
    "    model_RF.fit(X_train[selected_cols], Y_train)\n",
    "\n",
    "    rmse = RMSE(model_RF, select_col= selected_cols)\n",
    "\n",
    "    # save_model = 0 - модель не сохраняется\n",
    "    # save_model = 1 - модель сохраняется в любос случае\n",
    "    # save_model = 2 - модель сохраняется только если модель дает лучшие результаты\n",
    "    if save_model:\n",
    "        if save_model == 2: \n",
    "            try: #используем try если будет ошибка, например до этого не было сохраненной модели или были другие \n",
    "                #признаки в обучении, если срабатывает, то модель сохраняется, даже если не лучше\n",
    "                model_RF_ = joblib.load(\"model\\model_RF_general_file2\")\n",
    "                rmse_ = RMSE(model_RF_, select_col= selected_cols)\n",
    "                if rmse < rmse_:\n",
    "                    joblib.dump(model_RF, \"model\\model_RF_general_file2\")\n",
    "            except:\n",
    "                joblib.dump(model_RF, \"model\\model_RF_general_file2\")\n",
    "        else: # если подавалась единица \n",
    "            joblib.dump(model_RF, \"model\\model_RF_general_file2\")\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"time: {end - start:.2f} sec\")\n",
    "\n",
    "    return model_RF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3094ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general_model_RF\n",
      "Best params: {'max_depth': 11, 'min_samples_split': 3, 'n_estimators': 300}\n",
      "20387.45208907472\n",
      "time: 100.44 sec\n"
     ]
    }
   ],
   "source": [
    "model_RF = general_RF(save_model=2, title = \"general_model_RF\", selected_cols = best_feature_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4522f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_XGB(save_model=0, title=\"\", selected_cols=X_train.columns):\n",
    "    start = time.time()\n",
    "\n",
    "    if title:\n",
    "        print(title)\n",
    "\n",
    "    # Параметры для подбора\n",
    "    param_grid_XGB = {\n",
    "        'n_estimators': [100, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'gamma': [0, 1]\n",
    "    }\n",
    "\n",
    "    model_XGB = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    grid_search_XGB = GridSearchCV(\n",
    "        model_XGB,\n",
    "        param_grid=param_grid_XGB,\n",
    "        cv=4,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_XGB.fit(X_val[selected_cols], Y_val)\n",
    "\n",
    "    best_param = grid_search_XGB.best_params_\n",
    "\n",
    "    print(\"Best params:\", best_param)\n",
    "\n",
    "    model_XGB = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        random_state=42,\n",
    "        **best_param\n",
    "    )\n",
    "\n",
    "    model_XGB.fit(X_train[selected_cols], Y_train)\n",
    "\n",
    "    rmse = RMSE(model_XGB, select_col=selected_cols)\n",
    "\n",
    "    if save_model:\n",
    "        if save_model == 2:\n",
    "            try:\n",
    "                model_XGB_ = joblib.load(\"model/model_XGB_general_file2\")\n",
    "                rmse_ = RMSE(model_XGB_, select_col=selected_cols)\n",
    "                if rmse < rmse_:\n",
    "                    joblib.dump(model_XGB, \"model/model_XGB_general_file2\")\n",
    "            except:\n",
    "                joblib.dump(model_XGB, \"model/model_XGB_general_file2\")\n",
    "        else:\n",
    "            joblib.dump(model_XGB, \"model/model_XGB_general_file2\")\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"time: {end - start:.2f} sec\")\n",
    "\n",
    "    return model_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a857d6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general model XGB\n",
      "Best params: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
      "18641.74142610129\n",
      "time: 61.63 sec\n"
     ]
    }
   ],
   "source": [
    "model_XGB = general_XGB(save_model=2, title=\"general model XGB\", selected_cols= best_feature_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3023ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_KNN(save_model=0, title=\"\", selected_cols=X_train.columns):\n",
    "    start = time.time()\n",
    "\n",
    "    if title:\n",
    "        print(title)\n",
    "\n",
    "    param_grid_KNN = {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    model_KNN = KNeighborsRegressor()\n",
    "\n",
    "    grid_search_KNN = GridSearchCV(\n",
    "        model_KNN,\n",
    "        param_grid=param_grid_KNN,\n",
    "        cv=4,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_KNN.fit(X_val[selected_cols], Y_val)\n",
    "\n",
    "    best_params = grid_search_KNN.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "\n",
    "    model_KNN = KNeighborsRegressor(**best_params)\n",
    "    model_KNN.fit(X_train[selected_cols], Y_train)\n",
    "\n",
    "    predicted = np.expm1(model_KNN.predict(X_test[selected_cols]))\n",
    "    rmse = RMSE(model = model_KNN, select_col= selected_cols)\n",
    "\n",
    "    if save_model:\n",
    "        if save_model == 2:\n",
    "            try:\n",
    "                model_KNN_ = joblib.load(\"model/model_KNN_general_file2\")\n",
    "                rmse_ = RMSE(model_KNN_, select_col=selected_cols)\n",
    "                if rmse < rmse_:\n",
    "                    joblib.dump(model_KNN, \"model/model_KNN_general_file2\")\n",
    "            except:\n",
    "                joblib.dump(model_KNN, \"model/model_KNN_general_file2\")\n",
    "        else:\n",
    "            joblib.dump(model_KNN, \"model/model_KNN_general_file2\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"time: {end - start:.2f} sec\")\n",
    "\n",
    "    return model_KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44fac4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general model KNN\n",
      "Best params: {'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n",
      "37193.826779268544\n",
      "37193.826779268544\n",
      "time: 0.34 sec\n"
     ]
    }
   ],
   "source": [
    "model_KNN = general_KNN(save_model=2, title=\"general model KNN\", selected_cols= best_feature_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb74ef",
   "metadata": {},
   "source": [
    "# Создание окончательного предикта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "26011f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predict(data, model_KNN, model_RF, model_XGB, best_feature_KNN, best_feature_RF, best_feature_XGB):\n",
    "    predicted_XGB = np.expm1(model_XGB.predict(data[best_feature_XGB]))\n",
    "    predicted_RF = np.expm1(model_RF.predict(data[best_feature_RF]))\n",
    "    predicted_KNN = np.expm1(model_KNN.predict(data[best_feature_KNN]))\n",
    "\n",
    "    final_predict = predicted_XGB * 0.6 + predicted_RF * 0.3 + predicted_KNN * 0.1\n",
    "    \n",
    "    return final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6090d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = final_predict(X_test, model_KNN, model_RF, model_XGB, best_feature_KNN, best_feature_RF, best_feature_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c4d0d",
   "metadata": {},
   "source": [
    "# Сохранение результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c9f769f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predict(df, predict):\n",
    "    submission = pd.DataFrame({\n",
    "    \"Id\": df[\"Id\"],\n",
    "    \"SalePrice\": predict\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ad765",
   "metadata": {},
   "source": [
    "# Теперь делаем для тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "708ae4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальная размерность: (1459, 80)\n",
      "Количество пропусков: 7878\n",
      "Размерность после первичной обработки: (1459, 73)\n",
      "Количество пропусков: 642\n",
      "Размерность после вторичной обработки обработки: (1459, 73)\n",
      "Количество пропусков: 0\n",
      "\n",
      "Начало обработки категориальных признаков\n",
      "Количество признаков не переведенных в числовые: 0\n",
      "Обработка категориальных признаков закончена\n"
     ]
    }
   ],
   "source": [
    "df_t = pd.read_csv(r\"data\\test.csv\")\n",
    "feature = data_processing_NAN(df = df_t, test = 1)\n",
    "feature = data_processing_cat_features(feature= feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c8266df8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['RoofMatl_CompShg', 'Heating_GasA'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfeature\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_feature_XGB\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alexey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['RoofMatl_CompShg', 'Heating_GasA'] not in index\""
     ]
    }
   ],
   "source": [
    "feature[best_feature_XGB]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
